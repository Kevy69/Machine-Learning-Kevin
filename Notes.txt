ask:
    mini batch code implementation (wtf do i do?)


general notes:
    variable with a hat = known variable.


Linear regression:
    equation:
        y = a + bx +  (first degree)
        
        a = intercept
        b = slope
        y & x = predictions

    definitions:
        features: the variables where interested in.
        
        predictor/depedant variable: x
        response/indepedant variable: y

        residual(s): the distance(s) from the points to the line

    general:
        - most popular alg for calculating the regression line is the least squares alg.


Gradient descent:
    general:
        step size: slope(gradient) * learning rate

    batch gradient descent:
        equation: θⱼ₊₁ = θⱼ - n(2/m * Xᵀ (X * θⱼ - y))


polynomial regression:
    degree = increasing powers, getting more none linear
    order = dimentionality.
