{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.37454012, 0.95071431],\n",
       "        [0.73199394, 0.59865848],\n",
       "        [0.15601864, 0.15599452],\n",
       "        [0.05808361, 0.86617615],\n",
       "        [0.60111501, 0.70807258]]),\n",
       " (1000, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X = np.random.rand(1000, 2) # can use uniform or rand, doesn't really matter.\n",
    "X[0:5], X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = np.random.normal(0.1, size=1000)\n",
    "epsilon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = np.array([X[i][0] for i in range(len(X))])\n",
    "X2 = np.array([X[i][1] for i in range(len(X))])\n",
    "\n",
    "y = 3 * X1 + 5 * X2 + 3 + epsilon\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[np.ones(len(X)), X]\n",
    "X[0:3], X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((670, 2), (330, 2), (670,), (330,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape # X has two columns, so shape is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (2,1) doesn't match the broadcast shape (2,670)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m theta\n\u001b[0;32m     17\u001b[0m \u001b[39m# Get estimated b0 and b1 values by actually doing the batch gradient descent\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m theta \u001b[39m=\u001b[39m gradient_descent(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n\u001b[0;32m     20\u001b[0m theta\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# throws away additional dimension\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [7], line 14\u001b[0m, in \u001b[0;36mgradient_descent\u001b[1;34m(X, y, learning_rate, epochs)\u001b[0m\n\u001b[0;32m     11\u001b[0m     gradient \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m/\u001b[39m m \u001b[39m*\u001b[39m X\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m (X \u001b[39m@\u001b[39m theta \u001b[39m-\u001b[39m y) \u001b[39m# idk\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[39m# determine step size and use it next time we loop\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     theta \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m learning_rate\u001b[39m*\u001b[39mgradient \u001b[39m# learning_rate is eta in theory\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m theta\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (2,1) doesn't match the broadcast shape (2,670)"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Code-CYgrxAwh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d154d3528bab554518fce4b6bb47c23f2c1c42d729e7fb7463b0619040c8c50c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
