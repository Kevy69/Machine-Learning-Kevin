ask:
    mini batch code implementation (wtf do i do?)


General:
    Stuff one can do:
        Load Data
        Train test split
        Standardize data (feature scaling)

        linear/multiple regression

        polynomial regression (Arbitrarily add features)
        Regulirazation

        logistic regression
    

    False positive (FP) = falsely saying its positive. Saying patient has cancer, while he doesn't
    False negative (FN) = falsely saying its negative. Saying patient doesn't have cancer, while he does
    True positive (TP) = truly saying its positive. Saying patient has cancer, when he does.
    True negative (TN) = truly saying its negative. Saying patient doesn't have cancer, while he doesn't.

    accuracy = Part devided by whole.
    recall = TP/(TP+FN)
    precision = TP/(TP+FP)

    sensitivity = How often the test show a positive result, while patient has cancer.
    specificity = How often the test show a negative result, while patient doesn't have cancer.


    penalty = method to use. l1, l2 or elasticnet

    l1_ratio (alpha) = ratio of lasso and ridge to use. Starts with lasso, meaning a ratio of 0.9
                        would use 90% lasso and 10% ridge
                        
    regularization strength (c) = How hard the alg's will be on reducing/removing features (e.g how much to
                        increase bias and decrease varience). inversely proportional (lower = higher).




Linear regression:
    equation:
        y = a + bx +  (first degree)
        
        a = intercept
        b = slope
        y & x = predictions

    definitions:
        features: the variables where interested in.
        
        predictor/depedant variable: x
        response/indepedant variable: y

        residual(s): the distance(s) from the points to the line

    general:
        - most popular alg for calculating the regression line is the least squares alg.


Gradient descent:
    general:
        step size: slope(gradient) * learning rate

    batch gradient descent:
        equation: θⱼ₊₁ = θⱼ - n(2/m * Xᵀ (X * θⱼ - y))


polynomial regression:
    degree = increasing powers, getting more none linear
    order = dimentionality.
