{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "from lab2 import Helper\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>gender_2</th>\n",
       "      <th>bmi-feature_obese (class I)</th>\n",
       "      <th>bmi-feature_obese (class II)</th>\n",
       "      <th>bmi-feature_obese (class III)</th>\n",
       "      <th>bmi-feature_overweight</th>\n",
       "      <th>bp-feature_healthy</th>\n",
       "      <th>bp-feature_hypertension crises</th>\n",
       "      <th>bp-feature_stage 1 hypertension</th>\n",
       "      <th>bp-feature_stage 2 hypertension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  cholesterol  gluc  smoke  alco  active  cardio  gender_2  \\\n",
       "0   0  18393            1     1      0     0       1       0         1   \n",
       "1   1  20228            3     1      0     0       1       1         0   \n",
       "2   2  18857            3     1      0     0       0       1         0   \n",
       "\n",
       "   bmi-feature_obese (class I)  bmi-feature_obese (class II)  \\\n",
       "0                            0                             0   \n",
       "1                            1                             0   \n",
       "2                            0                             0   \n",
       "\n",
       "   bmi-feature_obese (class III)  bmi-feature_overweight  bp-feature_healthy  \\\n",
       "0                              0                       0                   0   \n",
       "1                              0                       0                   0   \n",
       "2                              0                       0                   0   \n",
       "\n",
       "   bp-feature_hypertension crises  bp-feature_stage 1 hypertension  \\\n",
       "0                               0                                1   \n",
       "1                               0                                0   \n",
       "2                               0                                1   \n",
       "\n",
       "   bp-feature_stage 2 hypertension  \n",
       "0                                0  \n",
       "1                                1  \n",
       "2                                0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>gender_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>21</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>34</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>23</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  bmi  ap_hi  ap_lo  cholesterol  gluc  smoke  alco  active  \\\n",
       "0   0  18393   21    110     80            1     1      0     0       1   \n",
       "1   1  20228   34    140     90            3     1      0     0       1   \n",
       "2   2  18857   23    130     70            3     1      0     0       0   \n",
       "\n",
       "   cardio  gender_2  \n",
       "0       0         1  \n",
       "1       1         0  \n",
       "2       1         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1 = pd.read_csv('Data/df1.csv')\n",
    "df2 = pd.read_csv('Data/df2.csv')\n",
    "\n",
    "display(df1.head(3), df2.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop id as its not useful\n",
    "df1 = df1.drop('id', axis=1)\n",
    "df2 = df2.drop('id', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - VÃ¤lja modell"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chosen models:\n",
    "* Logistic regression\n",
    "* decision tree\n",
    "* random forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train|validation|test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>gender_2</th>\n",
       "      <th>bmi-feature_obese (class I)</th>\n",
       "      <th>bmi-feature_obese (class II)</th>\n",
       "      <th>bmi-feature_obese (class III)</th>\n",
       "      <th>bmi-feature_overweight</th>\n",
       "      <th>bp-feature_healthy</th>\n",
       "      <th>bp-feature_hypertension crises</th>\n",
       "      <th>bp-feature_stage 1 hypertension</th>\n",
       "      <th>bp-feature_stage 2 hypertension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18393</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  cholesterol  gluc  smoke  alco  active  gender_2  \\\n",
       "0  18393            1     1      0     0       1         1   \n",
       "\n",
       "   bmi-feature_obese (class I)  bmi-feature_obese (class II)  \\\n",
       "0                            0                             0   \n",
       "\n",
       "   bmi-feature_obese (class III)  bmi-feature_overweight  bp-feature_healthy  \\\n",
       "0                              0                       0                   0   \n",
       "\n",
       "   bp-feature_hypertension crises  bp-feature_stage 1 hypertension  \\\n",
       "0                               0                                1   \n",
       "\n",
       "   bp-feature_stage 2 hypertension  \n",
       "0                                0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>gender_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18393</td>\n",
       "      <td>21</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  bmi  ap_hi  ap_lo  cholesterol  gluc  smoke  alco  active  gender_2\n",
       "0  18393   21    110     80            1     1      0     0       1         1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1_x, df1_y = df1.drop('cardio', axis=1), df1['cardio']\n",
    "df2_x, df2_y = df2.drop('cardio', axis=1), df2['cardio']\n",
    "\n",
    "display(\n",
    "    df1_x.head(1),\n",
    "    df2_x.head(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40918, 15), (40918,), (13640, 15), (13640,), (13640, 15), (13640,))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((40918, 10), (40918,), (13640, 10), (13640,), (13640, 10), (13640,))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1_x_train, df1_x_val, df1_x_test, df1_y_train, df1_y_val, df1_y_test = Helper.train_val_test_split(df1_x, df1_y, split_size=0.2, rand_state=42)\n",
    "df2_x_train, df2_x_val, df2_x_test, df2_y_train, df2_y_val, df2_y_test = Helper.train_val_test_split(df2_x, df2_y, split_size=0.2, rand_state=42)\n",
    "\n",
    "display(\n",
    "    (df1_x_train.shape, df1_y_train.shape, df1_x_val.shape, df1_y_val.shape, df1_x_test.shape, df1_y_test.shape),\n",
    "    (df2_x_train.shape, df2_y_train.shape, df2_x_val.shape, df2_y_val.shape, df2_x_test.shape, df2_y_test.shape),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24469073517266024,\n",
       " 0.4111901139656925,\n",
       " 0.24653791612942894,\n",
       " 0.4122246262036306)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_x_train, df1_x_val = Helper.scaler('minmax', df1_x_train, df1_x_val)\n",
    "df1_x_train.mean(), df1_x_train.std(), df1_x_val.mean(), df1_x_val.std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All paraters and explanations as to why i made the choices i made.\n",
    "###### NOTE: Obvious choices lack a \"Reason\" field.\n",
    "\n",
    "\n",
    "\n",
    "#### Grid Search parameters\n",
    "- Scoring: 'Accuracy'\n",
    "    - Reason: Given that where using classification based models, accuracy seems like the only appropriate metric, given it directly tells us how good the model's doing at actually classifying things correctly.\n",
    "- cv: 5\n",
    "    - Reason: After some online research, it seems as though 5 is a generally good number of folds for avoiding things like overfitting.\n",
    "\n",
    "#### LogisticRegression\n",
    "- Chosen parameters\n",
    "    - penalty: 'elasticnet'\n",
    "        - Reason: We'd like to use both L1 and or L2 regularization in the grid search.\n",
    "    \n",
    "    - solver: saga\n",
    "\n",
    "    - max_iter: 1000\n",
    "        - Reason: Some models require quite a few iterations before they converge. Given that max_iter only specifies the maximum number of allowed iterations before \"giving up\" on a model converging, we won't actually be wasting any compute power on running a more iterations than will be needed.\n",
    "\n",
    "- Hyperparameters\n",
    "\n",
    "    - l1_ratio: [0.0, 0.1, ... 1.0]\n",
    "        - Reason: Uses both solvers independently as well as in ratios with an increment resolution of 10%. This simply just seems like a resonable thing to do.\n",
    "    \n",
    "#### DecisionTreeClassifier\n",
    "- Chosen parameters\n",
    "    - max_depth: None (Default)\n",
    "        - Reason: Not needed as we'd like expand the nodes until all leaves are pure.\n",
    "\n",
    "    - min_samples_split: 2 (Default)\n",
    "        - Reason: We'd like to only split if we've got 2 samples or more \n",
    "\n",
    "    - min_samples_leaf: 1 (Default)\n",
    "        - Reason: We'd like our leaf nodes to only contain one sample\n",
    "\n",
    "    - min_weight_fraction_leaf: 0 (Default)\n",
    "        - Reason: We'd like to keep building the tree regardless of \"amount of data\" (so to say) available.\n",
    "\n",
    "    - max_leaf_nodes: None (Default)\n",
    "        - Reason: Generally not needed, as we'd simply like to build the tree until we've got pure leaves, not obsess about impurity decrease.\n",
    "\n",
    "    - min_impurity_decrease: 0 (Default)\n",
    "        - Reason: We'd like to keep splitting even if the impurity decrease is low. I dont think this will result in overfitting.\n",
    "\n",
    "    - class_weight: None (Default)\n",
    "        - Reason: We've got no clue about the importance of our classes.\n",
    "\n",
    "    - ccp_alpha: 0 (Default)\n",
    "        - Reason: Don't think we need this, as it won't meaningfully decrease the complexity of the tree.\n",
    "\n",
    "- Hyperparameters\n",
    "    - criterion ['gini', 'entropy', 'log_loss']\n",
    "    - splitter ['best', 'random']\n",
    "    - max_features: [None, 'sqrt', 'log2']\n",
    "\n",
    "\n",
    "#### RandomForestClassifier\n",
    "###### Note: Matching 'Chosen parameters' from above have been omitted, given the models both rely on decision trees. This is purely for aesthetics.\n",
    "- Chosen parameters\n",
    "\n",
    "    - bootstrap: True (Default)\n",
    "        - Reason: Part of what sets random forest and decision tree apart. So it'd be dumb to not use it.\n",
    "        \n",
    "    - oob_score: False (Default)\n",
    "        - Reason: Part of what sets random forest and decision tree apart. So it'd be dumb to not use it.\n",
    "\n",
    "- Hyperparameters\n",
    "    - n_estimators: [10, 20, ... 100]\n",
    "        - Reason: Seemed like a resonable range. Random forest doesn't \"slow down\" unlike some other algorithms, and eventually stabalizes, meaning you you won't gain anything by adding more trees. Our dataset also isnt particularly large or complex.\n",
    "    \n",
    "    - criterion ['gini', 'entropy', 'log_loss']\n",
    "    - max_features: [None, 'sqrt', 'log2']\n",
    "    \n",
    "    - max_samples: [None, 0.1, 0.2, ... 1.0] # would this actually work?\n",
    "        - Reason: We'll try all ratios, see what works best. Simple as that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 100, 150, 200, 250, 300]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [x for x in range(50, 350, 50)]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the data needed for chosing the right model and doing hyperparameter tuning via GridSearchCV\n",
    "\n",
    "datasets = {\n",
    "    'df1': {\n",
    "        'x_train': df1_x_train,\n",
    "        'x_val': df1_x_val,\n",
    "        'x_test': df1_x_test,\n",
    "        'y_train': df1_y_train,\n",
    "        'y_val': df1_y_val,\n",
    "        'y_test': df1_y_test\n",
    "    },\n",
    "    'df2': {\n",
    "        'x_train': df2_x_train,\n",
    "        'x_val': df2_x_val,\n",
    "        'x_test': df2_x_test,\n",
    "        'y_train': df2_y_train,\n",
    "        'y_val': df2_y_val,\n",
    "        'y_val': df2_y_test\n",
    "     }\n",
    "}\n",
    "\n",
    "\n",
    "model_data = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'search space': {\n",
    "            # Chosen parameters (defaults excluded)\n",
    "            'penalty': ['elasticnet'],\n",
    "            'solver': ['saga'],\n",
    "            'max_iter': 1000,\n",
    "            \n",
    "            # Hyperparamaters\n",
    "            'l1_ratio' : [round(x * 0.1, 1) for x in range(11)]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'DecisionTreeClassifier': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'search space': {\n",
    "            \n",
    "            # Hyperparamaters\n",
    "            'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "            'splitter': ['best', 'random'],\n",
    "            'max_features' : [None, 'sqrt', 'log2'],\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'RandomForestClassifier': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'search space': {\n",
    "            \n",
    "            # Hyperparamaters\n",
    "            'n_estimators': [x for x in range(10, 110, 10)],\n",
    "            \n",
    "            'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "            'max_features' : [None, 'sqrt', 'log2']\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Scaling</th>\n",
       "      <th>Model</th>\n",
       "      <th>Hyper params</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Dataset, Scaling, Model, Hyper params, Accuracy]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics = pd.DataFrame(columns=['Dataset', 'Scaling', 'Model', 'Hyper params', 'Accuracy'])\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "[CV 1/5] END l1_ratio=0.0, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.3s\n",
      "[CV 2/5] END l1_ratio=0.0, penalty=elasticnet, solver=saga;, score=0.693 total time=   0.1s\n",
      "[CV 3/5] END l1_ratio=0.0, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 4/5] END l1_ratio=0.0, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.2s\n",
      "[CV 5/5] END l1_ratio=0.0, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.2s\n",
      "[CV 1/5] END l1_ratio=0.1, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.2s\n",
      "[CV 2/5] END l1_ratio=0.1, penalty=elasticnet, solver=saga;, score=0.693 total time=   0.2s\n",
      "[CV 3/5] END l1_ratio=0.1, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 4/5] END l1_ratio=0.1, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.2s\n",
      "[CV 5/5] END l1_ratio=0.1, penalty=elasticnet, solver=saga;, score=0.711 total time=   0.2s\n",
      "[CV 1/5] END l1_ratio=0.2, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.3s\n",
      "[CV 2/5] END l1_ratio=0.2, penalty=elasticnet, solver=saga;, score=0.693 total time=   0.2s\n",
      "[CV 3/5] END l1_ratio=0.2, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.3s\n",
      "[CV 4/5] END l1_ratio=0.2, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.2s\n",
      "[CV 5/5] END l1_ratio=0.2, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.2s\n",
      "[CV 1/5] END l1_ratio=0.3, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.2s\n",
      "[CV 2/5] END l1_ratio=0.3, penalty=elasticnet, solver=saga;, score=0.693 total time=   0.3s\n",
      "[CV 3/5] END l1_ratio=0.3, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 4/5] END l1_ratio=0.3, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.3s\n",
      "[CV 5/5] END l1_ratio=0.3, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.2s\n",
      "[CV 1/5] END l1_ratio=0.4, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.3s\n",
      "[CV 2/5] END l1_ratio=0.4, penalty=elasticnet, solver=saga;, score=0.693 total time=   0.2s\n",
      "[CV 3/5] END l1_ratio=0.4, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 4/5] END l1_ratio=0.4, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.4s\n",
      "[CV 5/5] END l1_ratio=0.4, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.2s\n",
      "[CV 1/5] END l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.3s\n",
      "[CV 2/5] END l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.693 total time=   0.2s\n",
      "[CV 3/5] END l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 4/5] END l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.2s\n",
      "[CV 5/5] END l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.2s\n",
      "[CV 1/5] END l1_ratio=0.6, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.2s\n",
      "[CV 2/5] END l1_ratio=0.6, penalty=elasticnet, solver=saga;, score=0.693 total time=   0.2s\n",
      "[CV 3/5] END l1_ratio=0.6, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 4/5] END l1_ratio=0.6, penalty=elasticnet, solver=saga;, score=0.701 total time=   0.2s\n",
      "[CV 5/5] END l1_ratio=0.6, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.3s\n",
      "[CV 1/5] END l1_ratio=0.7, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.2s\n",
      "[CV 2/5] END l1_ratio=0.7, penalty=elasticnet, solver=saga;, score=0.693 total time=   0.3s\n",
      "[CV 3/5] END l1_ratio=0.7, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 4/5] END l1_ratio=0.7, penalty=elasticnet, solver=saga;, score=0.701 total time=   0.2s\n",
      "[CV 5/5] END l1_ratio=0.7, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.2s\n",
      "[CV 1/5] END l1_ratio=0.8, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.3s\n",
      "[CV 2/5] END l1_ratio=0.8, penalty=elasticnet, solver=saga;, score=0.693 total time=   0.3s\n",
      "[CV 3/5] END l1_ratio=0.8, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 4/5] END l1_ratio=0.8, penalty=elasticnet, solver=saga;, score=0.701 total time=   0.3s\n",
      "[CV 5/5] END l1_ratio=0.8, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.3s\n",
      "[CV 1/5] END l1_ratio=0.9, penalty=elasticnet, solver=saga;, score=0.697 total time=   0.3s\n",
      "[CV 2/5] END l1_ratio=0.9, penalty=elasticnet, solver=saga;, score=0.693 total time=   0.2s\n",
      "[CV 3/5] END l1_ratio=0.9, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.3s\n",
      "[CV 4/5] END l1_ratio=0.9, penalty=elasticnet, solver=saga;, score=0.701 total time=   0.2s\n",
      "[CV 5/5] END l1_ratio=0.9, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.3s\n",
      "[CV 1/5] END l1_ratio=1.0, penalty=elasticnet, solver=saga;, score=0.697 total time=   0.2s\n",
      "[CV 2/5] END l1_ratio=1.0, penalty=elasticnet, solver=saga;, score=0.693 total time=   0.2s\n",
      "[CV 3/5] END l1_ratio=1.0, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 4/5] END l1_ratio=1.0, penalty=elasticnet, solver=saga;, score=0.701 total time=   0.2s\n",
      "[CV 5/5] END l1_ratio=1.0, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.2s\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END criterion=gini, max_features=None, splitter=best;, score=0.606 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_features=None, splitter=best;, score=0.609 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_features=None, splitter=best;, score=0.606 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_features=None, splitter=best;, score=0.612 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_features=None, splitter=best;, score=0.608 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_features=None, splitter=random;, score=0.601 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_features=None, splitter=random;, score=0.602 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_features=None, splitter=random;, score=0.615 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_features=None, splitter=random;, score=0.611 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_features=None, splitter=random;, score=0.609 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, splitter=best;, score=0.606 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, splitter=best;, score=0.609 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, splitter=best;, score=0.618 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, splitter=best;, score=0.608 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, splitter=best;, score=0.609 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, splitter=random;, score=0.603 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, splitter=random;, score=0.609 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, splitter=random;, score=0.613 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, splitter=random;, score=0.608 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, splitter=random;, score=0.608 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, splitter=best;, score=0.607 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, splitter=best;, score=0.607 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, splitter=best;, score=0.614 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, splitter=best;, score=0.611 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, splitter=best;, score=0.611 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, splitter=random;, score=0.603 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, splitter=random;, score=0.604 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, splitter=random;, score=0.611 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, splitter=random;, score=0.611 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, splitter=random;, score=0.610 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_features=None, splitter=best;, score=0.605 total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_features=None, splitter=best;, score=0.612 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_features=None, splitter=best;, score=0.612 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_features=None, splitter=best;, score=0.611 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_features=None, splitter=best;, score=0.607 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_features=None, splitter=random;, score=0.598 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_features=None, splitter=random;, score=0.608 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_features=None, splitter=random;, score=0.617 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_features=None, splitter=random;, score=0.609 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_features=None, splitter=random;, score=0.610 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, splitter=best;, score=0.602 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, splitter=best;, score=0.609 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, splitter=best;, score=0.616 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, splitter=best;, score=0.610 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, splitter=best;, score=0.612 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, splitter=random;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, splitter=random;, score=0.607 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, splitter=random;, score=0.613 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, splitter=random;, score=0.605 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, splitter=random;, score=0.611 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, splitter=best;, score=0.608 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, splitter=best;, score=0.606 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, splitter=best;, score=0.614 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, splitter=best;, score=0.612 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, splitter=best;, score=0.611 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, splitter=random;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, splitter=random;, score=0.610 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, splitter=random;, score=0.616 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, splitter=random;, score=0.613 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, splitter=random;, score=0.608 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_features=None, splitter=best;, score=0.605 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_features=None, splitter=best;, score=0.613 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_features=None, splitter=best;, score=0.611 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_features=None, splitter=best;, score=0.613 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_features=None, splitter=best;, score=0.608 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_features=None, splitter=random;, score=0.604 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_features=None, splitter=random;, score=0.604 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_features=None, splitter=random;, score=0.613 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_features=None, splitter=random;, score=0.608 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_features=None, splitter=random;, score=0.608 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_features=sqrt, splitter=best;, score=0.607 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_features=sqrt, splitter=best;, score=0.609 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_features=sqrt, splitter=best;, score=0.613 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_features=sqrt, splitter=best;, score=0.612 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_features=sqrt, splitter=best;, score=0.611 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_features=sqrt, splitter=random;, score=0.606 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_features=sqrt, splitter=random;, score=0.605 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_features=sqrt, splitter=random;, score=0.615 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_features=sqrt, splitter=random;, score=0.611 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_features=sqrt, splitter=random;, score=0.609 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_features=log2, splitter=best;, score=0.606 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_features=log2, splitter=best;, score=0.607 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_features=log2, splitter=best;, score=0.611 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_features=log2, splitter=best;, score=0.609 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_features=log2, splitter=best;, score=0.608 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_features=log2, splitter=random;, score=0.604 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_features=log2, splitter=random;, score=0.612 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_features=log2, splitter=random;, score=0.616 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_features=log2, splitter=random;, score=0.609 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_features=log2, splitter=random;, score=0.613 total time=   0.0s\n",
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "[CV 1/5] END criterion=gini, max_features=None, n_estimators=10;, score=0.632 total time=   1.4s\n",
      "[CV 2/5] END criterion=gini, max_features=None, n_estimators=10;, score=0.631 total time=   1.4s\n",
      "[CV 3/5] END criterion=gini, max_features=None, n_estimators=10;, score=0.635 total time=   1.4s\n",
      "[CV 4/5] END criterion=gini, max_features=None, n_estimators=10;, score=0.634 total time=   1.4s\n",
      "[CV 5/5] END criterion=gini, max_features=None, n_estimators=10;, score=0.631 total time=   1.4s\n",
      "[CV 1/5] END criterion=gini, max_features=None, n_estimators=20;, score=0.629 total time=   3.3s\n",
      "[CV 2/5] END criterion=gini, max_features=None, n_estimators=20;, score=0.639 total time=   3.0s\n",
      "[CV 3/5] END criterion=gini, max_features=None, n_estimators=20;, score=0.632 total time=   3.0s\n",
      "[CV 4/5] END criterion=gini, max_features=None, n_estimators=20;, score=0.639 total time=   3.1s\n",
      "[CV 5/5] END criterion=gini, max_features=None, n_estimators=20;, score=0.636 total time=   3.0s\n",
      "[CV 1/5] END criterion=gini, max_features=None, n_estimators=30;, score=0.632 total time=   4.6s\n",
      "[CV 2/5] END criterion=gini, max_features=None, n_estimators=30;, score=0.630 total time=   4.6s\n",
      "[CV 3/5] END criterion=gini, max_features=None, n_estimators=30;, score=0.634 total time=   4.6s\n",
      "[CV 4/5] END criterion=gini, max_features=None, n_estimators=30;, score=0.646 total time=   4.5s\n",
      "[CV 5/5] END criterion=gini, max_features=None, n_estimators=30;, score=0.633 total time=   4.6s\n",
      "[CV 1/5] END criterion=gini, max_features=None, n_estimators=40;, score=0.633 total time=   6.2s\n",
      "[CV 2/5] END criterion=gini, max_features=None, n_estimators=40;, score=0.640 total time=   6.2s\n",
      "[CV 3/5] END criterion=gini, max_features=None, n_estimators=40;, score=0.640 total time=   6.1s\n",
      "[CV 4/5] END criterion=gini, max_features=None, n_estimators=40;, score=0.646 total time=   6.1s\n",
      "[CV 5/5] END criterion=gini, max_features=None, n_estimators=40;, score=0.637 total time=   6.1s\n",
      "[CV 1/5] END criterion=gini, max_features=None, n_estimators=50;, score=0.633 total time=   7.8s\n",
      "[CV 2/5] END criterion=gini, max_features=None, n_estimators=50;, score=0.637 total time=   7.6s\n",
      "[CV 3/5] END criterion=gini, max_features=None, n_estimators=50;, score=0.638 total time=   7.7s\n",
      "[CV 4/5] END criterion=gini, max_features=None, n_estimators=50;, score=0.643 total time=   7.6s\n",
      "[CV 5/5] END criterion=gini, max_features=None, n_estimators=50;, score=0.637 total time=   7.8s\n",
      "[CV 1/5] END criterion=gini, max_features=None, n_estimators=60;, score=0.633 total time=   9.2s\n",
      "[CV 2/5] END criterion=gini, max_features=None, n_estimators=60;, score=0.636 total time=   9.3s\n",
      "[CV 3/5] END criterion=gini, max_features=None, n_estimators=60;, score=0.640 total time=   9.2s\n",
      "[CV 4/5] END criterion=gini, max_features=None, n_estimators=60;, score=0.645 total time=  10.4s\n",
      "[CV 5/5] END criterion=gini, max_features=None, n_estimators=60;, score=0.638 total time=   9.2s\n",
      "[CV 1/5] END criterion=gini, max_features=None, n_estimators=70;, score=0.637 total time=  10.7s\n",
      "[CV 2/5] END criterion=gini, max_features=None, n_estimators=70;, score=0.639 total time=  10.9s\n",
      "[CV 3/5] END criterion=gini, max_features=None, n_estimators=70;, score=0.640 total time=  10.4s\n",
      "[CV 4/5] END criterion=gini, max_features=None, n_estimators=70;, score=0.648 total time=  12.8s\n",
      "[CV 5/5] END criterion=gini, max_features=None, n_estimators=70;, score=0.639 total time=  11.3s\n",
      "[CV 1/5] END criterion=gini, max_features=None, n_estimators=80;, score=0.634 total time=  12.7s\n",
      "[CV 2/5] END criterion=gini, max_features=None, n_estimators=80;, score=0.638 total time=  12.9s\n",
      "[CV 3/5] END criterion=gini, max_features=None, n_estimators=80;, score=0.641 total time=  12.7s\n",
      "[CV 4/5] END criterion=gini, max_features=None, n_estimators=80;, score=0.646 total time=  12.6s\n",
      "[CV 5/5] END criterion=gini, max_features=None, n_estimators=80;, score=0.636 total time=  13.1s\n",
      "[CV 1/5] END criterion=gini, max_features=None, n_estimators=90;, score=0.632 total time=  14.3s\n",
      "[CV 2/5] END criterion=gini, max_features=None, n_estimators=90;, score=0.638 total time=  14.3s\n",
      "[CV 3/5] END criterion=gini, max_features=None, n_estimators=90;, score=0.642 total time=  14.2s\n",
      "[CV 4/5] END criterion=gini, max_features=None, n_estimators=90;, score=0.646 total time=  14.2s\n",
      "[CV 5/5] END criterion=gini, max_features=None, n_estimators=90;, score=0.639 total time=  14.3s\n",
      "[CV 1/5] END criterion=gini, max_features=None, n_estimators=100;, score=0.635 total time=  16.2s\n",
      "[CV 2/5] END criterion=gini, max_features=None, n_estimators=100;, score=0.637 total time=  16.0s\n",
      "[CV 3/5] END criterion=gini, max_features=None, n_estimators=100;, score=0.639 total time=  15.7s\n",
      "[CV 4/5] END criterion=gini, max_features=None, n_estimators=100;, score=0.647 total time=  15.8s\n",
      "[CV 5/5] END criterion=gini, max_features=None, n_estimators=100;, score=0.638 total time=  15.9s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, n_estimators=10;, score=0.615 total time=   0.7s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, n_estimators=10;, score=0.617 total time=   0.7s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, n_estimators=10;, score=0.623 total time=   0.7s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, n_estimators=10;, score=0.622 total time=   0.7s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, n_estimators=10;, score=0.621 total time=   0.7s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, n_estimators=20;, score=0.614 total time=   1.5s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, n_estimators=20;, score=0.616 total time=   1.6s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, n_estimators=20;, score=0.623 total time=   1.5s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, n_estimators=20;, score=0.622 total time=   1.5s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, n_estimators=20;, score=0.619 total time=   1.5s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, n_estimators=30;, score=0.612 total time=   3.0s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, n_estimators=30;, score=0.614 total time=   2.9s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, n_estimators=30;, score=0.621 total time=   2.3s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, n_estimators=30;, score=0.618 total time=   2.8s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, n_estimators=30;, score=0.620 total time=   2.3s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, n_estimators=40;, score=0.610 total time=   3.0s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, n_estimators=40;, score=0.616 total time=   3.1s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, n_estimators=40;, score=0.617 total time=   3.0s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, n_estimators=40;, score=0.618 total time=   3.1s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, n_estimators=40;, score=0.617 total time=   3.2s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, n_estimators=50;, score=0.612 total time=   3.7s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, n_estimators=50;, score=0.615 total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, n_estimators=50;, score=0.616 total time=   3.7s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, n_estimators=50;, score=0.618 total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, n_estimators=50;, score=0.616 total time=   3.9s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, n_estimators=60;, score=0.610 total time=   4.7s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, n_estimators=60;, score=0.611 total time=   4.5s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, n_estimators=60;, score=0.617 total time=   5.1s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, n_estimators=60;, score=0.619 total time=   4.7s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, n_estimators=60;, score=0.615 total time=   4.6s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, n_estimators=70;, score=0.610 total time=   5.5s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, n_estimators=70;, score=0.612 total time=   5.4s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, n_estimators=70;, score=0.617 total time=   5.3s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, n_estimators=70;, score=0.618 total time=   5.4s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, n_estimators=70;, score=0.616 total time=   5.6s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, n_estimators=80;, score=0.611 total time=   6.2s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, n_estimators=80;, score=0.614 total time=   6.2s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, n_estimators=80;, score=0.619 total time=   6.1s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, n_estimators=80;, score=0.617 total time=   6.2s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, n_estimators=80;, score=0.617 total time=   6.3s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, n_estimators=90;, score=0.610 total time=   6.8s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, n_estimators=90;, score=0.614 total time=   6.9s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, n_estimators=90;, score=0.618 total time=   6.9s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, n_estimators=90;, score=0.617 total time=   7.1s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, n_estimators=90;, score=0.617 total time=   6.9s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, n_estimators=100;, score=0.608 total time=   7.7s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, n_estimators=100;, score=0.613 total time=   8.0s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, n_estimators=100;, score=0.618 total time=   7.9s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, n_estimators=100;, score=0.617 total time=   7.8s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, n_estimators=100;, score=0.617 total time=   7.9s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, n_estimators=10;, score=0.613 total time=   0.7s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, n_estimators=10;, score=0.614 total time=   0.7s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, n_estimators=10;, score=0.621 total time=   0.7s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, n_estimators=10;, score=0.618 total time=   0.7s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, n_estimators=10;, score=0.617 total time=   0.7s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, n_estimators=20;, score=0.611 total time=   1.5s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, n_estimators=20;, score=0.615 total time=   1.5s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, n_estimators=20;, score=0.620 total time=   1.5s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, n_estimators=20;, score=0.619 total time=   1.5s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, n_estimators=20;, score=0.622 total time=   1.6s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, n_estimators=30;, score=0.613 total time=   2.3s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, n_estimators=30;, score=0.614 total time=   2.4s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, n_estimators=30;, score=0.618 total time=   2.3s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, n_estimators=30;, score=0.617 total time=   2.3s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, n_estimators=30;, score=0.618 total time=   2.4s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, n_estimators=40;, score=0.612 total time=   3.0s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, n_estimators=40;, score=0.614 total time=   3.1s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, n_estimators=40;, score=0.620 total time=   3.1s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, n_estimators=40;, score=0.619 total time=   3.0s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, n_estimators=40;, score=0.618 total time=   3.1s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, n_estimators=50;, score=0.610 total time=   3.9s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, n_estimators=50;, score=0.613 total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, n_estimators=50;, score=0.619 total time=   3.8s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, n_estimators=50;, score=0.621 total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, n_estimators=50;, score=0.616 total time=   3.8s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, n_estimators=60;, score=0.610 total time=   4.7s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, n_estimators=60;, score=0.612 total time=   4.6s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, n_estimators=60;, score=0.619 total time=   4.7s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, n_estimators=60;, score=0.620 total time=   5.0s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, n_estimators=60;, score=0.616 total time=   4.7s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, n_estimators=70;, score=0.608 total time=   5.4s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, n_estimators=70;, score=0.615 total time=   5.4s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, n_estimators=70;, score=0.619 total time=   6.2s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, n_estimators=70;, score=0.619 total time=   6.1s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, n_estimators=70;, score=0.616 total time=   5.6s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, n_estimators=80;, score=0.610 total time=   6.1s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, n_estimators=80;, score=0.613 total time=   6.1s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, n_estimators=80;, score=0.617 total time=   6.2s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, n_estimators=80;, score=0.618 total time=   6.3s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, n_estimators=80;, score=0.617 total time=   6.3s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, n_estimators=90;, score=0.608 total time=   7.0s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, n_estimators=90;, score=0.613 total time=   7.0s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, n_estimators=90;, score=0.619 total time=   7.3s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, n_estimators=90;, score=0.618 total time=   7.0s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, n_estimators=90;, score=0.616 total time=   7.0s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, n_estimators=100;, score=0.609 total time=   7.9s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, n_estimators=100;, score=0.612 total time=   7.7s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, n_estimators=100;, score=0.618 total time=   7.8s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, n_estimators=100;, score=0.617 total time=   7.8s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, n_estimators=100;, score=0.616 total time=   8.4s\n",
      "[CV 1/5] END criterion=entropy, max_features=None, n_estimators=10;, score=0.631 total time=   2.0s\n",
      "[CV 2/5] END criterion=entropy, max_features=None, n_estimators=10;, score=0.630 total time=   2.1s\n",
      "[CV 3/5] END criterion=entropy, max_features=None, n_estimators=10;, score=0.635 total time=   2.4s\n",
      "[CV 4/5] END criterion=entropy, max_features=None, n_estimators=10;, score=0.644 total time=   2.0s\n",
      "[CV 5/5] END criterion=entropy, max_features=None, n_estimators=10;, score=0.634 total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_features=None, n_estimators=20;, score=0.633 total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_features=None, n_estimators=20;, score=0.636 total time=   4.1s\n",
      "[CV 3/5] END criterion=entropy, max_features=None, n_estimators=20;, score=0.635 total time=   4.0s\n",
      "[CV 4/5] END criterion=entropy, max_features=None, n_estimators=20;, score=0.640 total time=   4.1s\n",
      "[CV 5/5] END criterion=entropy, max_features=None, n_estimators=20;, score=0.634 total time=   4.1s\n",
      "[CV 1/5] END criterion=entropy, max_features=None, n_estimators=30;, score=0.632 total time=   6.4s\n",
      "[CV 2/5] END criterion=entropy, max_features=None, n_estimators=30;, score=0.641 total time=   6.7s\n",
      "[CV 3/5] END criterion=entropy, max_features=None, n_estimators=30;, score=0.640 total time=   6.1s\n",
      "[CV 4/5] END criterion=entropy, max_features=None, n_estimators=30;, score=0.649 total time=   6.0s\n",
      "[CV 5/5] END criterion=entropy, max_features=None, n_estimators=30;, score=0.640 total time=   6.2s\n",
      "[CV 1/5] END criterion=entropy, max_features=None, n_estimators=40;, score=0.640 total time=   8.3s\n",
      "[CV 2/5] END criterion=entropy, max_features=None, n_estimators=40;, score=0.639 total time=   8.3s\n",
      "[CV 3/5] END criterion=entropy, max_features=None, n_estimators=40;, score=0.641 total time=   8.2s\n",
      "[CV 4/5] END criterion=entropy, max_features=None, n_estimators=40;, score=0.644 total time=   8.1s\n",
      "[CV 5/5] END criterion=entropy, max_features=None, n_estimators=40;, score=0.635 total time=   8.4s\n",
      "[CV 1/5] END criterion=entropy, max_features=None, n_estimators=50;, score=0.636 total time=  10.4s\n",
      "[CV 2/5] END criterion=entropy, max_features=None, n_estimators=50;, score=0.640 total time=  10.6s\n",
      "[CV 3/5] END criterion=entropy, max_features=None, n_estimators=50;, score=0.643 total time=  10.4s\n",
      "[CV 4/5] END criterion=entropy, max_features=None, n_estimators=50;, score=0.646 total time=  10.2s\n",
      "[CV 5/5] END criterion=entropy, max_features=None, n_estimators=50;, score=0.637 total time=  10.6s\n",
      "[CV 1/5] END criterion=entropy, max_features=None, n_estimators=60;, score=0.636 total time=  12.3s\n",
      "[CV 2/5] END criterion=entropy, max_features=None, n_estimators=60;, score=0.636 total time=  12.4s\n",
      "[CV 3/5] END criterion=entropy, max_features=None, n_estimators=60;, score=0.641 total time=  13.5s\n",
      "[CV 4/5] END criterion=entropy, max_features=None, n_estimators=60;, score=0.645 total time=  12.6s\n",
      "[CV 5/5] END criterion=entropy, max_features=None, n_estimators=60;, score=0.638 total time=  12.7s\n",
      "[CV 1/5] END criterion=entropy, max_features=None, n_estimators=70;, score=0.636 total time=  15.8s\n",
      "[CV 2/5] END criterion=entropy, max_features=None, n_estimators=70;, score=0.636 total time=  15.3s\n",
      "[CV 3/5] END criterion=entropy, max_features=None, n_estimators=70;, score=0.643 total time=  14.2s\n",
      "[CV 4/5] END criterion=entropy, max_features=None, n_estimators=70;, score=0.649 total time=  14.4s\n",
      "[CV 5/5] END criterion=entropy, max_features=None, n_estimators=70;, score=0.642 total time=  14.9s\n",
      "[CV 1/5] END criterion=entropy, max_features=None, n_estimators=80;, score=0.637 total time=  16.6s\n",
      "[CV 2/5] END criterion=entropy, max_features=None, n_estimators=80;, score=0.636 total time=  16.7s\n",
      "[CV 3/5] END criterion=entropy, max_features=None, n_estimators=80;, score=0.644 total time=  16.6s\n",
      "[CV 4/5] END criterion=entropy, max_features=None, n_estimators=80;, score=0.648 total time=  16.3s\n",
      "[CV 5/5] END criterion=entropy, max_features=None, n_estimators=80;, score=0.643 total time=  16.6s\n",
      "[CV 1/5] END criterion=entropy, max_features=None, n_estimators=90;, score=0.637 total time=  18.9s\n",
      "[CV 2/5] END criterion=entropy, max_features=None, n_estimators=90;, score=0.640 total time=  18.6s\n",
      "[CV 3/5] END criterion=entropy, max_features=None, n_estimators=90;, score=0.644 total time=  18.4s\n",
      "[CV 4/5] END criterion=entropy, max_features=None, n_estimators=90;, score=0.645 total time=  18.7s\n",
      "[CV 5/5] END criterion=entropy, max_features=None, n_estimators=90;, score=0.639 total time=  19.0s\n",
      "[CV 1/5] END criterion=entropy, max_features=None, n_estimators=100;, score=0.637 total time=  22.3s\n",
      "[CV 2/5] END criterion=entropy, max_features=None, n_estimators=100;, score=0.636 total time=  20.6s\n",
      "[CV 3/5] END criterion=entropy, max_features=None, n_estimators=100;, score=0.643 total time=  20.4s\n",
      "[CV 4/5] END criterion=entropy, max_features=None, n_estimators=100;, score=0.646 total time=  20.6s\n",
      "[CV 5/5] END criterion=entropy, max_features=None, n_estimators=100;, score=0.640 total time=  21.2s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, n_estimators=10;, score=0.620 total time=   1.0s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, n_estimators=10;, score=0.617 total time=   0.9s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, n_estimators=10;, score=0.623 total time=   0.9s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, n_estimators=10;, score=0.617 total time=   0.9s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, n_estimators=10;, score=0.622 total time=   1.0s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, n_estimators=20;, score=0.612 total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, n_estimators=20;, score=0.614 total time=   2.3s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, n_estimators=20;, score=0.622 total time=   2.5s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, n_estimators=20;, score=0.619 total time=   2.2s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, n_estimators=20;, score=0.617 total time=   2.4s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, n_estimators=30;, score=0.609 total time=   3.7s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, n_estimators=30;, score=0.613 total time=   3.5s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, n_estimators=30;, score=0.617 total time=   3.3s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, n_estimators=30;, score=0.619 total time=   3.8s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, n_estimators=30;, score=0.618 total time=   3.9s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, n_estimators=40;, score=0.608 total time=   5.1s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, n_estimators=40;, score=0.613 total time=   4.9s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, n_estimators=40;, score=0.620 total time=   5.3s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, n_estimators=40;, score=0.617 total time=   4.9s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, n_estimators=40;, score=0.616 total time=   4.3s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, n_estimators=50;, score=0.610 total time=   5.8s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, n_estimators=50;, score=0.613 total time=   6.0s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, n_estimators=50;, score=0.618 total time=   5.4s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, n_estimators=50;, score=0.620 total time=   5.2s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, n_estimators=50;, score=0.618 total time=   5.1s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, n_estimators=60;, score=0.611 total time=   6.2s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, n_estimators=60;, score=0.615 total time=   6.2s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, n_estimators=60;, score=0.617 total time=   6.3s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, n_estimators=60;, score=0.619 total time=   6.8s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, n_estimators=60;, score=0.617 total time=   7.4s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, n_estimators=70;, score=0.609 total time=   7.7s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, n_estimators=70;, score=0.615 total time=   7.8s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, n_estimators=70;, score=0.620 total time=   7.4s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, n_estimators=70;, score=0.618 total time=   7.2s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, n_estimators=70;, score=0.615 total time=   7.1s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, n_estimators=80;, score=0.610 total time=   8.1s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, n_estimators=80;, score=0.611 total time=   8.0s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, n_estimators=80;, score=0.618 total time=   7.8s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, n_estimators=80;, score=0.618 total time=   7.8s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, n_estimators=80;, score=0.618 total time=   8.0s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, n_estimators=90;, score=0.611 total time=   8.9s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, n_estimators=90;, score=0.612 total time=   9.9s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, n_estimators=90;, score=0.619 total time=  11.3s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, n_estimators=90;, score=0.617 total time=  10.5s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, n_estimators=90;, score=0.615 total time=  10.8s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, n_estimators=100;, score=0.608 total time=  11.7s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, n_estimators=100;, score=0.613 total time=  10.3s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, n_estimators=100;, score=0.618 total time=  10.0s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, n_estimators=100;, score=0.619 total time=  10.9s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, n_estimators=100;, score=0.617 total time=  11.1s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, n_estimators=10;, score=0.619 total time=   0.9s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, n_estimators=10;, score=0.618 total time=   1.0s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, n_estimators=10;, score=0.625 total time=   1.0s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, n_estimators=10;, score=0.620 total time=   1.1s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, n_estimators=10;, score=0.620 total time=   1.0s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, n_estimators=20;, score=0.614 total time=   2.2s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, n_estimators=20;, score=0.615 total time=   2.1s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, n_estimators=20;, score=0.620 total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, n_estimators=20;, score=0.621 total time=   2.0s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, n_estimators=20;, score=0.622 total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, n_estimators=30;, score=0.612 total time=   3.3s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, n_estimators=30;, score=0.615 total time=   3.7s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, n_estimators=30;, score=0.620 total time=   3.3s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, n_estimators=30;, score=0.619 total time=   3.4s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, n_estimators=30;, score=0.619 total time=   3.1s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, n_estimators=40;, score=0.610 total time=   4.8s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, n_estimators=40;, score=0.613 total time=   4.5s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, n_estimators=40;, score=0.617 total time=   5.0s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, n_estimators=40;, score=0.618 total time=   4.2s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, n_estimators=40;, score=0.618 total time=   4.2s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, n_estimators=50;, score=0.612 total time=   5.0s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, n_estimators=50;, score=0.613 total time=   5.0s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, n_estimators=50;, score=0.618 total time=   5.3s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, n_estimators=50;, score=0.617 total time=   5.0s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, n_estimators=50;, score=0.617 total time=   5.1s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, n_estimators=60;, score=0.611 total time=   6.3s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, n_estimators=60;, score=0.613 total time=   6.1s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, n_estimators=60;, score=0.619 total time=   6.1s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, n_estimators=60;, score=0.619 total time=   6.2s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, n_estimators=60;, score=0.618 total time=   6.1s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, n_estimators=70;, score=0.611 total time=   7.1s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, n_estimators=70;, score=0.613 total time=   7.4s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, n_estimators=70;, score=0.618 total time=   7.1s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, n_estimators=70;, score=0.618 total time=   7.1s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, n_estimators=70;, score=0.617 total time=   7.0s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, n_estimators=80;, score=0.609 total time=   8.1s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, n_estimators=80;, score=0.614 total time=   8.4s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, n_estimators=80;, score=0.620 total time=   8.3s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, n_estimators=80;, score=0.616 total time=   8.3s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, n_estimators=80;, score=0.619 total time=   8.3s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, n_estimators=90;, score=0.608 total time=   9.6s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, n_estimators=90;, score=0.612 total time=   9.2s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, n_estimators=90;, score=0.618 total time=  10.6s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, n_estimators=90;, score=0.618 total time=   9.3s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, n_estimators=90;, score=0.618 total time=   9.4s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, n_estimators=100;, score=0.610 total time=  10.7s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, n_estimators=100;, score=0.613 total time=  10.5s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, n_estimators=100;, score=0.618 total time=  10.2s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, n_estimators=100;, score=0.618 total time=  10.2s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, n_estimators=100;, score=0.615 total time=  10.1s\n",
      "[CV 1/5] END criterion=log_loss, max_features=None, n_estimators=10;, score=0.631 total time=   2.0s\n",
      "[CV 2/5] END criterion=log_loss, max_features=None, n_estimators=10;, score=0.632 total time=   2.0s\n",
      "[CV 3/5] END criterion=log_loss, max_features=None, n_estimators=10;, score=0.637 total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_features=None, n_estimators=10;, score=0.634 total time=   2.0s\n",
      "[CV 5/5] END criterion=log_loss, max_features=None, n_estimators=10;, score=0.630 total time=   2.4s\n",
      "[CV 1/5] END criterion=log_loss, max_features=None, n_estimators=20;, score=0.634 total time=   4.0s\n",
      "[CV 2/5] END criterion=log_loss, max_features=None, n_estimators=20;, score=0.635 total time=   4.0s\n",
      "[CV 3/5] END criterion=log_loss, max_features=None, n_estimators=20;, score=0.642 total time=   4.0s\n",
      "[CV 4/5] END criterion=log_loss, max_features=None, n_estimators=20;, score=0.645 total time=   4.0s\n",
      "[CV 5/5] END criterion=log_loss, max_features=None, n_estimators=20;, score=0.640 total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_features=None, n_estimators=30;, score=0.631 total time=   6.1s\n",
      "[CV 2/5] END criterion=log_loss, max_features=None, n_estimators=30;, score=0.636 total time=   6.0s\n",
      "[CV 3/5] END criterion=log_loss, max_features=None, n_estimators=30;, score=0.637 total time=   5.9s\n",
      "[CV 4/5] END criterion=log_loss, max_features=None, n_estimators=30;, score=0.646 total time=   6.3s\n",
      "[CV 5/5] END criterion=log_loss, max_features=None, n_estimators=30;, score=0.642 total time=   6.3s\n",
      "[CV 1/5] END criterion=log_loss, max_features=None, n_estimators=40;, score=0.633 total time=   8.1s\n",
      "[CV 2/5] END criterion=log_loss, max_features=None, n_estimators=40;, score=0.638 total time=   8.1s\n",
      "[CV 3/5] END criterion=log_loss, max_features=None, n_estimators=40;, score=0.638 total time=   8.2s\n",
      "[CV 4/5] END criterion=log_loss, max_features=None, n_estimators=40;, score=0.649 total time=   7.9s\n",
      "[CV 5/5] END criterion=log_loss, max_features=None, n_estimators=40;, score=0.639 total time=   8.4s\n",
      "[CV 1/5] END criterion=log_loss, max_features=None, n_estimators=50;, score=0.635 total time=  10.3s\n",
      "[CV 2/5] END criterion=log_loss, max_features=None, n_estimators=50;, score=0.642 total time=  10.4s\n",
      "[CV 3/5] END criterion=log_loss, max_features=None, n_estimators=50;, score=0.638 total time=  10.4s\n",
      "[CV 4/5] END criterion=log_loss, max_features=None, n_estimators=50;, score=0.644 total time=  10.2s\n",
      "[CV 5/5] END criterion=log_loss, max_features=None, n_estimators=50;, score=0.642 total time=  10.2s\n",
      "[CV 1/5] END criterion=log_loss, max_features=None, n_estimators=60;, score=0.639 total time=  12.5s\n",
      "[CV 2/5] END criterion=log_loss, max_features=None, n_estimators=60;, score=0.640 total time=  12.2s\n",
      "[CV 3/5] END criterion=log_loss, max_features=None, n_estimators=60;, score=0.642 total time=  12.3s\n",
      "[CV 4/5] END criterion=log_loss, max_features=None, n_estimators=60;, score=0.649 total time=  13.1s\n",
      "[CV 5/5] END criterion=log_loss, max_features=None, n_estimators=60;, score=0.638 total time=  12.6s\n",
      "[CV 1/5] END criterion=log_loss, max_features=None, n_estimators=70;, score=0.634 total time=  15.6s\n",
      "[CV 2/5] END criterion=log_loss, max_features=None, n_estimators=70;, score=0.639 total time=  14.8s\n",
      "[CV 3/5] END criterion=log_loss, max_features=None, n_estimators=70;, score=0.640 total time=  14.2s\n",
      "[CV 4/5] END criterion=log_loss, max_features=None, n_estimators=70;, score=0.650 total time=  14.2s\n",
      "[CV 5/5] END criterion=log_loss, max_features=None, n_estimators=70;, score=0.641 total time=  14.8s\n",
      "[CV 1/5] END criterion=log_loss, max_features=None, n_estimators=80;, score=0.638 total time=  16.6s\n",
      "[CV 2/5] END criterion=log_loss, max_features=None, n_estimators=80;, score=0.640 total time=  16.6s\n",
      "[CV 3/5] END criterion=log_loss, max_features=None, n_estimators=80;, score=0.642 total time=  16.4s\n",
      "[CV 4/5] END criterion=log_loss, max_features=None, n_estimators=80;, score=0.648 total time=  16.6s\n",
      "[CV 5/5] END criterion=log_loss, max_features=None, n_estimators=80;, score=0.640 total time=  16.6s\n",
      "[CV 1/5] END criterion=log_loss, max_features=None, n_estimators=90;, score=0.639 total time=  19.0s\n",
      "[CV 2/5] END criterion=log_loss, max_features=None, n_estimators=90;, score=0.642 total time=  18.8s\n",
      "[CV 3/5] END criterion=log_loss, max_features=None, n_estimators=90;, score=0.642 total time=  18.4s\n",
      "[CV 4/5] END criterion=log_loss, max_features=None, n_estimators=90;, score=0.648 total time=  18.5s\n",
      "[CV 5/5] END criterion=log_loss, max_features=None, n_estimators=90;, score=0.643 total time=  18.5s\n",
      "[CV 1/5] END criterion=log_loss, max_features=None, n_estimators=100;, score=0.638 total time=  20.7s\n",
      "[CV 2/5] END criterion=log_loss, max_features=None, n_estimators=100;, score=0.641 total time=  20.7s\n",
      "[CV 3/5] END criterion=log_loss, max_features=None, n_estimators=100;, score=0.642 total time=  21.0s\n",
      "[CV 4/5] END criterion=log_loss, max_features=None, n_estimators=100;, score=0.647 total time=  22.2s\n",
      "[CV 5/5] END criterion=log_loss, max_features=None, n_estimators=100;, score=0.642 total time=  21.2s\n",
      "[CV 1/5] END criterion=log_loss, max_features=sqrt, n_estimators=10;, score=0.615 total time=   0.9s\n",
      "[CV 2/5] END criterion=log_loss, max_features=sqrt, n_estimators=10;, score=0.614 total time=   1.0s\n",
      "[CV 3/5] END criterion=log_loss, max_features=sqrt, n_estimators=10;, score=0.617 total time=   0.9s\n",
      "[CV 4/5] END criterion=log_loss, max_features=sqrt, n_estimators=10;, score=0.620 total time=   0.9s\n",
      "[CV 5/5] END criterion=log_loss, max_features=sqrt, n_estimators=10;, score=0.620 total time=   0.9s\n",
      "[CV 1/5] END criterion=log_loss, max_features=sqrt, n_estimators=20;, score=0.611 total time=   2.0s\n",
      "[CV 2/5] END criterion=log_loss, max_features=sqrt, n_estimators=20;, score=0.617 total time=   2.0s\n",
      "[CV 3/5] END criterion=log_loss, max_features=sqrt, n_estimators=20;, score=0.622 total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_features=sqrt, n_estimators=20;, score=0.618 total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_features=sqrt, n_estimators=20;, score=0.617 total time=   1.9s\n",
      "[CV 1/5] END criterion=log_loss, max_features=sqrt, n_estimators=30;, score=0.612 total time=   3.1s\n",
      "[CV 2/5] END criterion=log_loss, max_features=sqrt, n_estimators=30;, score=0.617 total time=   3.0s\n",
      "[CV 3/5] END criterion=log_loss, max_features=sqrt, n_estimators=30;, score=0.620 total time=   3.0s\n",
      "[CV 4/5] END criterion=log_loss, max_features=sqrt, n_estimators=30;, score=0.617 total time=   3.1s\n",
      "[CV 5/5] END criterion=log_loss, max_features=sqrt, n_estimators=30;, score=0.619 total time=   3.0s\n",
      "[CV 1/5] END criterion=log_loss, max_features=sqrt, n_estimators=40;, score=0.611 total time=   4.4s\n",
      "[CV 2/5] END criterion=log_loss, max_features=sqrt, n_estimators=40;, score=0.613 total time=   4.1s\n",
      "[CV 3/5] END criterion=log_loss, max_features=sqrt, n_estimators=40;, score=0.619 total time=   4.2s\n",
      "[CV 4/5] END criterion=log_loss, max_features=sqrt, n_estimators=40;, score=0.620 total time=   4.0s\n",
      "[CV 5/5] END criterion=log_loss, max_features=sqrt, n_estimators=40;, score=0.617 total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_features=sqrt, n_estimators=50;, score=0.610 total time=   5.1s\n",
      "[CV 2/5] END criterion=log_loss, max_features=sqrt, n_estimators=50;, score=0.615 total time=   5.1s\n",
      "[CV 3/5] END criterion=log_loss, max_features=sqrt, n_estimators=50;, score=0.620 total time=   4.9s\n",
      "[CV 4/5] END criterion=log_loss, max_features=sqrt, n_estimators=50;, score=0.619 total time=   4.9s\n",
      "[CV 5/5] END criterion=log_loss, max_features=sqrt, n_estimators=50;, score=0.614 total time=   5.1s\n",
      "[CV 1/5] END criterion=log_loss, max_features=sqrt, n_estimators=60;, score=0.610 total time=   6.4s\n",
      "[CV 2/5] END criterion=log_loss, max_features=sqrt, n_estimators=60;, score=0.614 total time=   6.2s\n",
      "[CV 3/5] END criterion=log_loss, max_features=sqrt, n_estimators=60;, score=0.619 total time=   6.1s\n",
      "[CV 4/5] END criterion=log_loss, max_features=sqrt, n_estimators=60;, score=0.617 total time=   6.2s\n",
      "[CV 5/5] END criterion=log_loss, max_features=sqrt, n_estimators=60;, score=0.615 total time=   6.1s\n",
      "[CV 1/5] END criterion=log_loss, max_features=sqrt, n_estimators=70;, score=0.608 total time=   7.1s\n",
      "[CV 2/5] END criterion=log_loss, max_features=sqrt, n_estimators=70;, score=0.614 total time=   7.2s\n",
      "[CV 3/5] END criterion=log_loss, max_features=sqrt, n_estimators=70;, score=0.618 total time=   7.1s\n",
      "[CV 4/5] END criterion=log_loss, max_features=sqrt, n_estimators=70;, score=0.619 total time=   7.1s\n",
      "[CV 5/5] END criterion=log_loss, max_features=sqrt, n_estimators=70;, score=0.617 total time=   7.1s\n",
      "[CV 1/5] END criterion=log_loss, max_features=sqrt, n_estimators=80;, score=0.612 total time=   8.1s\n",
      "[CV 2/5] END criterion=log_loss, max_features=sqrt, n_estimators=80;, score=0.612 total time=   8.1s\n",
      "[CV 3/5] END criterion=log_loss, max_features=sqrt, n_estimators=80;, score=0.619 total time=   8.2s\n",
      "[CV 4/5] END criterion=log_loss, max_features=sqrt, n_estimators=80;, score=0.620 total time=   8.5s\n",
      "[CV 5/5] END criterion=log_loss, max_features=sqrt, n_estimators=80;, score=0.615 total time=   8.2s\n",
      "[CV 1/5] END criterion=log_loss, max_features=sqrt, n_estimators=90;, score=0.610 total time=   9.3s\n",
      "[CV 2/5] END criterion=log_loss, max_features=sqrt, n_estimators=90;, score=0.613 total time=   9.3s\n",
      "[CV 3/5] END criterion=log_loss, max_features=sqrt, n_estimators=90;, score=0.616 total time=   9.3s\n",
      "[CV 4/5] END criterion=log_loss, max_features=sqrt, n_estimators=90;, score=0.617 total time=   9.1s\n",
      "[CV 5/5] END criterion=log_loss, max_features=sqrt, n_estimators=90;, score=0.617 total time=   9.3s\n",
      "[CV 1/5] END criterion=log_loss, max_features=sqrt, n_estimators=100;, score=0.609 total time=  10.1s\n",
      "[CV 2/5] END criterion=log_loss, max_features=sqrt, n_estimators=100;, score=0.612 total time=  10.3s\n",
      "[CV 3/5] END criterion=log_loss, max_features=sqrt, n_estimators=100;, score=0.619 total time=  11.9s\n",
      "[CV 4/5] END criterion=log_loss, max_features=sqrt, n_estimators=100;, score=0.617 total time=  10.1s\n",
      "[CV 5/5] END criterion=log_loss, max_features=sqrt, n_estimators=100;, score=0.616 total time=  10.3s\n",
      "[CV 1/5] END criterion=log_loss, max_features=log2, n_estimators=10;, score=0.615 total time=   1.0s\n",
      "[CV 2/5] END criterion=log_loss, max_features=log2, n_estimators=10;, score=0.619 total time=   1.0s\n",
      "[CV 3/5] END criterion=log_loss, max_features=log2, n_estimators=10;, score=0.621 total time=   1.0s\n",
      "[CV 4/5] END criterion=log_loss, max_features=log2, n_estimators=10;, score=0.623 total time=   1.0s\n",
      "[CV 5/5] END criterion=log_loss, max_features=log2, n_estimators=10;, score=0.620 total time=   0.9s\n",
      "[CV 1/5] END criterion=log_loss, max_features=log2, n_estimators=20;, score=0.612 total time=   2.0s\n",
      "[CV 2/5] END criterion=log_loss, max_features=log2, n_estimators=20;, score=0.613 total time=   2.1s\n",
      "[CV 3/5] END criterion=log_loss, max_features=log2, n_estimators=20;, score=0.621 total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_features=log2, n_estimators=20;, score=0.622 total time=   2.0s\n",
      "[CV 5/5] END criterion=log_loss, max_features=log2, n_estimators=20;, score=0.622 total time=   2.0s\n",
      "[CV 1/5] END criterion=log_loss, max_features=log2, n_estimators=30;, score=0.612 total time=   3.0s\n",
      "[CV 2/5] END criterion=log_loss, max_features=log2, n_estimators=30;, score=0.615 total time=   3.1s\n",
      "[CV 3/5] END criterion=log_loss, max_features=log2, n_estimators=30;, score=0.622 total time=   3.1s\n",
      "[CV 4/5] END criterion=log_loss, max_features=log2, n_estimators=30;, score=0.618 total time=   3.0s\n",
      "[CV 5/5] END criterion=log_loss, max_features=log2, n_estimators=30;, score=0.619 total time=   3.0s\n",
      "[CV 1/5] END criterion=log_loss, max_features=log2, n_estimators=40;, score=0.611 total time=   4.1s\n",
      "[CV 2/5] END criterion=log_loss, max_features=log2, n_estimators=40;, score=0.614 total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_features=log2, n_estimators=40;, score=0.617 total time=   4.0s\n",
      "[CV 4/5] END criterion=log_loss, max_features=log2, n_estimators=40;, score=0.623 total time=   4.0s\n",
      "[CV 5/5] END criterion=log_loss, max_features=log2, n_estimators=40;, score=0.617 total time=   4.0s\n",
      "[CV 1/5] END criterion=log_loss, max_features=log2, n_estimators=50;, score=0.609 total time=   5.2s\n",
      "[CV 2/5] END criterion=log_loss, max_features=log2, n_estimators=50;, score=0.614 total time=   5.1s\n",
      "[CV 3/5] END criterion=log_loss, max_features=log2, n_estimators=50;, score=0.619 total time=   5.1s\n",
      "[CV 4/5] END criterion=log_loss, max_features=log2, n_estimators=50;, score=0.619 total time=   5.5s\n",
      "[CV 5/5] END criterion=log_loss, max_features=log2, n_estimators=50;, score=0.616 total time=   5.1s\n",
      "[CV 1/5] END criterion=log_loss, max_features=log2, n_estimators=60;, score=0.610 total time=   6.1s\n",
      "[CV 2/5] END criterion=log_loss, max_features=log2, n_estimators=60;, score=0.613 total time=   6.2s\n",
      "[CV 3/5] END criterion=log_loss, max_features=log2, n_estimators=60;, score=0.619 total time=   6.1s\n",
      "[CV 4/5] END criterion=log_loss, max_features=log2, n_estimators=60;, score=0.617 total time=   6.1s\n",
      "[CV 5/5] END criterion=log_loss, max_features=log2, n_estimators=60;, score=0.616 total time=   6.1s\n",
      "[CV 1/5] END criterion=log_loss, max_features=log2, n_estimators=70;, score=0.611 total time=   7.1s\n",
      "[CV 2/5] END criterion=log_loss, max_features=log2, n_estimators=70;, score=0.615 total time=   7.3s\n",
      "[CV 3/5] END criterion=log_loss, max_features=log2, n_estimators=70;, score=0.618 total time=   7.1s\n",
      "[CV 4/5] END criterion=log_loss, max_features=log2, n_estimators=70;, score=0.618 total time=   7.2s\n",
      "[CV 5/5] END criterion=log_loss, max_features=log2, n_estimators=70;, score=0.617 total time=   7.2s\n",
      "[CV 1/5] END criterion=log_loss, max_features=log2, n_estimators=80;, score=0.610 total time=   8.2s\n",
      "[CV 2/5] END criterion=log_loss, max_features=log2, n_estimators=80;, score=0.614 total time=   8.4s\n",
      "[CV 3/5] END criterion=log_loss, max_features=log2, n_estimators=80;, score=0.618 total time=   8.2s\n",
      "[CV 4/5] END criterion=log_loss, max_features=log2, n_estimators=80;, score=0.617 total time=   8.1s\n",
      "[CV 5/5] END criterion=log_loss, max_features=log2, n_estimators=80;, score=0.617 total time=   8.2s\n",
      "[CV 1/5] END criterion=log_loss, max_features=log2, n_estimators=90;, score=0.608 total time=   9.1s\n",
      "[CV 2/5] END criterion=log_loss, max_features=log2, n_estimators=90;, score=0.612 total time=   9.4s\n",
      "[CV 3/5] END criterion=log_loss, max_features=log2, n_estimators=90;, score=0.617 total time=   9.2s\n",
      "[CV 4/5] END criterion=log_loss, max_features=log2, n_estimators=90;, score=0.617 total time=   9.4s\n",
      "[CV 5/5] END criterion=log_loss, max_features=log2, n_estimators=90;, score=0.617 total time=   9.4s\n",
      "[CV 1/5] END criterion=log_loss, max_features=log2, n_estimators=100;, score=0.608 total time=  12.1s\n",
      "[CV 2/5] END criterion=log_loss, max_features=log2, n_estimators=100;, score=0.612 total time=  11.5s\n",
      "[CV 3/5] END criterion=log_loss, max_features=log2, n_estimators=100;, score=0.619 total time=  10.6s\n",
      "[CV 4/5] END criterion=log_loss, max_features=log2, n_estimators=100;, score=0.618 total time=  14.3s\n",
      "[CV 5/5] END criterion=log_loss, max_features=log2, n_estimators=100;, score=0.616 total time=  10.6s\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "[CV 1/5] END l1_ratio=0.0, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.1s\n",
      "[CV 2/5] END l1_ratio=0.0, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.1s\n",
      "[CV 3/5] END l1_ratio=0.0, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.1s\n",
      "[CV 4/5] END l1_ratio=0.0, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.1s\n",
      "[CV 5/5] END l1_ratio=0.0, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.1s\n",
      "[CV 1/5] END l1_ratio=0.1, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.2s\n",
      "[CV 2/5] END l1_ratio=0.1, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 3/5] END l1_ratio=0.1, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 4/5] END l1_ratio=0.1, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.2s\n",
      "[CV 5/5] END l1_ratio=0.1, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.2s\n",
      "[CV 1/5] END l1_ratio=0.2, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.2s\n",
      "[CV 2/5] END l1_ratio=0.2, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.3s\n",
      "[CV 3/5] END l1_ratio=0.2, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 4/5] END l1_ratio=0.2, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.2s\n",
      "[CV 5/5] END l1_ratio=0.2, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.2s\n",
      "[CV 1/5] END l1_ratio=0.3, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.2s\n",
      "[CV 2/5] END l1_ratio=0.3, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 3/5] END l1_ratio=0.3, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 4/5] END l1_ratio=0.3, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.2s\n",
      "[CV 5/5] END l1_ratio=0.3, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.2s\n",
      "[CV 1/5] END l1_ratio=0.4, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.2s\n",
      "[CV 2/5] END l1_ratio=0.4, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 3/5] END l1_ratio=0.4, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 4/5] END l1_ratio=0.4, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.2s\n",
      "[CV 5/5] END l1_ratio=0.4, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.3s\n",
      "[CV 1/5] END l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.3s\n",
      "[CV 2/5] END l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 3/5] END l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.4s\n",
      "[CV 4/5] END l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.2s\n",
      "[CV 5/5] END l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.3s\n",
      "[CV 1/5] END l1_ratio=0.6, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.4s\n",
      "[CV 2/5] END l1_ratio=0.6, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 3/5] END l1_ratio=0.6, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 4/5] END l1_ratio=0.6, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.3s\n",
      "[CV 5/5] END l1_ratio=0.6, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.2s\n",
      "[CV 1/5] END l1_ratio=0.7, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.2s\n",
      "[CV 2/5] END l1_ratio=0.7, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 3/5] END l1_ratio=0.7, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 4/5] END l1_ratio=0.7, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.3s\n",
      "[CV 5/5] END l1_ratio=0.7, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.2s\n",
      "[CV 1/5] END l1_ratio=0.8, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.2s\n",
      "[CV 2/5] END l1_ratio=0.8, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.2s\n",
      "[CV 3/5] END l1_ratio=0.8, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.3s\n",
      "[CV 4/5] END l1_ratio=0.8, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.3s\n",
      "[CV 5/5] END l1_ratio=0.8, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.2s\n",
      "[CV 1/5] END l1_ratio=0.9, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.3s\n",
      "[CV 2/5] END l1_ratio=0.9, penalty=elasticnet, solver=saga;, score=0.692 total time=   3.5s\n",
      "[CV 3/5] END l1_ratio=0.9, penalty=elasticnet, solver=saga;, score=0.692 total time=   2.4s\n",
      "[CV 4/5] END l1_ratio=0.9, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.8s\n",
      "[CV 5/5] END l1_ratio=0.9, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.7s\n",
      "[CV 1/5] END l1_ratio=1.0, penalty=elasticnet, solver=saga;, score=0.696 total time=   0.6s\n",
      "[CV 2/5] END l1_ratio=1.0, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.5s\n",
      "[CV 3/5] END l1_ratio=1.0, penalty=elasticnet, solver=saga;, score=0.692 total time=   0.4s\n",
      "[CV 4/5] END l1_ratio=1.0, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.4s\n",
      "[CV 5/5] END l1_ratio=1.0, penalty=elasticnet, solver=saga;, score=0.710 total time=   0.4s\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END criterion=gini, max_features=None, splitter=best;, score=0.609 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_features=None, splitter=best;, score=0.606 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_features=None, splitter=best;, score=0.609 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_features=None, splitter=best;, score=0.614 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_features=None, splitter=best;, score=0.607 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_features=None, splitter=random;, score=0.602 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_features=None, splitter=random;, score=0.608 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_features=None, splitter=random;, score=0.615 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_features=None, splitter=random;, score=0.607 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_features=None, splitter=random;, score=0.605 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, splitter=best;, score=0.605 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, splitter=best;, score=0.610 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, splitter=best;, score=0.615 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, splitter=best;, score=0.611 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, splitter=best;, score=0.611 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, splitter=random;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, splitter=random;, score=0.605 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, splitter=random;, score=0.615 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, splitter=random;, score=0.609 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, splitter=random;, score=0.609 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, splitter=best;, score=0.609 total time=180.0min\n",
      "[CV 2/5] END criterion=gini, max_features=log2, splitter=best;, score=0.606 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, splitter=best;, score=0.616 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, splitter=best;, score=0.610 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, splitter=best;, score=0.611 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, splitter=random;, score=0.609 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, splitter=random;, score=0.608 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, splitter=random;, score=0.617 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, splitter=random;, score=0.603 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, splitter=random;, score=0.612 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_features=None, splitter=best;, score=0.607 total time=   0.4s\n",
      "[CV 2/5] END criterion=entropy, max_features=None, splitter=best;, score=0.609 total time=   0.3s\n",
      "[CV 3/5] END criterion=entropy, max_features=None, splitter=best;, score=0.612 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_features=None, splitter=best;, score=0.613 total time=   0.5s\n",
      "[CV 5/5] END criterion=entropy, max_features=None, splitter=best;, score=0.609 total time=   0.5s\n",
      "[CV 1/5] END criterion=entropy, max_features=None, splitter=random;, score=0.604 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_features=None, splitter=random;, score=0.607 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_features=None, splitter=random;, score=0.606 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_features=None, splitter=random;, score=0.607 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_features=None, splitter=random;, score=0.610 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, splitter=best;, score=0.610 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, splitter=best;, score=0.604 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, splitter=best;, score=0.614 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, splitter=best;, score=0.613 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, splitter=best;, score=0.610 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, splitter=random;, score=0.609 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, splitter=random;, score=0.615 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, splitter=random;, score=0.612 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, splitter=random;, score=0.612 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, splitter=random;, score=0.614 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, splitter=best;, score=0.606 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, splitter=best;, score=0.606 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, splitter=best;, score=0.615 total time=   0.3s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, splitter=best;, score=0.615 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, splitter=best;, score=0.611 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, splitter=random;, score=0.609 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, splitter=random;, score=0.608 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, splitter=random;, score=0.615 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, splitter=random;, score=0.612 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, splitter=random;, score=0.603 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_features=None, splitter=best;, score=0.607 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_features=None, splitter=best;, score=0.608 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_features=None, splitter=best;, score=0.610 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_features=None, splitter=best;, score=0.617 total time=   0.4s\n",
      "[CV 5/5] END criterion=log_loss, max_features=None, splitter=best;, score=0.607 total time=   0.4s\n",
      "[CV 1/5] END criterion=log_loss, max_features=None, splitter=random;, score=0.600 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_features=None, splitter=random;, score=0.613 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_features=None, splitter=random;, score=0.617 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_features=None, splitter=random;, score=0.611 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_features=None, splitter=random;, score=0.611 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_features=sqrt, splitter=best;, score=0.603 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_features=sqrt, splitter=best;, score=0.606 total time=1314.2min\n",
      "[CV 3/5] END criterion=log_loss, max_features=sqrt, splitter=best;, score=0.613 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_features=sqrt, splitter=best;, score=0.611 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_features=sqrt, splitter=best;, score=0.611 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_features=sqrt, splitter=random;, score=0.605 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_features=sqrt, splitter=random;, score=0.609 total time=   0.4s\n",
      "[CV 3/5] END criterion=log_loss, max_features=sqrt, splitter=random;, score=0.612 total time=   0.3s\n",
      "[CV 4/5] END criterion=log_loss, max_features=sqrt, splitter=random;, score=0.607 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_features=sqrt, splitter=random;, score=0.611 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_features=log2, splitter=best;, score=0.609 total time=   0.8s\n",
      "[CV 2/5] END criterion=log_loss, max_features=log2, splitter=best;, score=0.607 total time=   0.7s\n",
      "[CV 3/5] END criterion=log_loss, max_features=log2, splitter=best;, score=0.614 total time=   0.7s\n",
      "[CV 4/5] END criterion=log_loss, max_features=log2, splitter=best;, score=0.611 total time=   0.6s\n",
      "[CV 5/5] END criterion=log_loss, max_features=log2, splitter=best;, score=0.608 total time=   0.4s\n",
      "[CV 1/5] END criterion=log_loss, max_features=log2, splitter=random;, score=0.605 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_features=log2, splitter=random;, score=0.612 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_features=log2, splitter=random;, score=0.616 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_features=log2, splitter=random;, score=0.611 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_features=log2, splitter=random;, score=0.606 total time=   0.1s\n",
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "[CV 1/5] END criterion=gini, max_features=None, n_estimators=10;, score=0.629 total time=   3.7s\n",
      "[CV 2/5] END criterion=gini, max_features=None, n_estimators=10;, score=0.637 total time=   3.7s\n",
      "[CV 3/5] END criterion=gini, max_features=None, n_estimators=10;, score=0.635 total time=   3.5s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Kevin\\Documents\\School\\Code\\Machine-Learning-Kevin\\Lab\\Lab part 2 (2.4 - VÃ¤lja modell).ipynb Cell 14\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kevin/Documents/School/Code/Machine-Learning-Kevin/Lab/Lab%20part%202%20%282.4%20-%20V%C3%A4lja%20modell%29.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m model_name, data \u001b[39min\u001b[39;00m model_data\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kevin/Documents/School/Code/Machine-Learning-Kevin/Lab/Lab%20part%202%20%282.4%20-%20V%C3%A4lja%20modell%29.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kevin/Documents/School/Code/Machine-Learning-Kevin/Lab/Lab%20part%202%20%282.4%20-%20V%C3%A4lja%20modell%29.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# Search # find the best hyperparamters\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kevin/Documents/School/Code/Machine-Learning-Kevin/Lab/Lab%20part%202%20%282.4%20-%20V%C3%A4lja%20modell%29.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     GS \u001b[39m=\u001b[39m GridSearchCV(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kevin/Documents/School/Code/Machine-Learning-Kevin/Lab/Lab%20part%202%20%282.4%20-%20V%C3%A4lja%20modell%29.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         estimator \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kevin/Documents/School/Code/Machine-Learning-Kevin/Lab/Lab%20part%202%20%282.4%20-%20V%C3%A4lja%20modell%29.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         param_grid \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39msearch space\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kevin/Documents/School/Code/Machine-Learning-Kevin/Lab/Lab%20part%202%20%282.4%20-%20V%C3%A4lja%20modell%29.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         verbose \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kevin/Documents/School/Code/Machine-Learning-Kevin/Lab/Lab%20part%202%20%282.4%20-%20V%C3%A4lja%20modell%29.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Kevin/Documents/School/Code/Machine-Learning-Kevin/Lab/Lab%20part%202%20%282.4%20-%20V%C3%A4lja%20modell%29.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     GS\u001b[39m.\u001b[39;49mfit(scaled_x_train, dataset[\u001b[39m'\u001b[39;49m\u001b[39my_train\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kevin/Documents/School/Code/Machine-Learning-Kevin/Lab/Lab%20part%202%20%282.4%20-%20V%C3%A4lja%20modell%29.ipynb#X13sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     val_pred \u001b[39m=\u001b[39m GS\u001b[39m.\u001b[39mpredict(scaled_x_val)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kevin/Documents/School/Code/Machine-Learning-Kevin/Lab/Lab%20part%202%20%282.4%20-%20V%C3%A4lja%20modell%29.ipynb#X13sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     score \u001b[39m=\u001b[39m accuracy_score(dataset[\u001b[39m'\u001b[39m\u001b[39my_val\u001b[39m\u001b[39m'\u001b[39m], val_pred)\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    477\u001b[0m )(\n\u001b[0;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    479\u001b[0m         t,\n\u001b[0;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    481\u001b[0m         X,\n\u001b[0;32m    482\u001b[0m         y,\n\u001b[0;32m    483\u001b[0m         sample_weight,\n\u001b[0;32m    484\u001b[0m         i,\n\u001b[0;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "model_metrics = pd.DataFrame(columns=['Dataset', 'Scaling', 'Model', 'Hyper params', 'Accuracy'])\n",
    "model_metrics\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    \n",
    "    # Loop through and use the minmax and standard scaler\n",
    "    for scaler_name in ['minmax', 'standard']:\n",
    "        \n",
    "        # Scale the data\n",
    "        scaled_x_train, scaled_x_val = Helper.scaler(scaler_name, dataset['x_train'], dataset['x_val'])\n",
    "\n",
    "        # loop through all models. data = dict with model object and parameter info\n",
    "        for model_name, data in model_data.items():\n",
    "            \n",
    "            # Search # find the best hyperparamters\n",
    "            GS = GridSearchCV(\n",
    "                estimator = data['model'],\n",
    "                param_grid = data['search space'],\n",
    "                scoring = 'accuracy',\n",
    "                #n_jobs=2, # add when running final\n",
    "                cv = 5,\n",
    "                verbose = 3 # remove when running final\n",
    "            )\n",
    "            \n",
    "            GS.fit(scaled_x_train, dataset['y_train'])\n",
    "            \n",
    "            val_pred = GS.predict(scaled_x_val)\n",
    "            \n",
    "            score = accuracy_score(dataset['y_val'], val_pred)\n",
    "            \n",
    "            model_metrics.loc[len(model_metrics.index)] = [\n",
    "                dataset_name,\n",
    "                scaler_name,\n",
    "                model_name,\n",
    "                GS.best_params_,\n",
    "                score\n",
    "            ]\n",
    "            \n",
    "\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anvÃ¤nda GridSearchCV() och vÃ¤lja lÃ¤mplig evalueringsmetric (accurancy)\n",
    "# gÃ¶r prediction pÃ¥ valideringsdata\n",
    "# berÃ¤kna och spara evaluation score fÃ¶r ditt valda metric\n",
    "# checka bÃ¤sta parametrarna fÃ¶r respektive modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kevin\\.virtualenvs\\Code-CYgrxAwh\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(df1_x_train, df1_y_train)\n",
    "y_pred = clf.predict(df1_x_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(classification_report(df1_y_test, y_pred))\n",
    "# cm = confusion_matrix(df1_y_test, y_pred)\n",
    "# ConfusionMatrixDisplay(cm).plot();\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Code-CYgrxAwh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d154d3528bab554518fce4b6bb47c23f2c1c42d729e7fb7463b0619040c8c50c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
