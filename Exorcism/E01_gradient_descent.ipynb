{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 2),\n",
       " array([[0.37454012, 0.95071431],\n",
       "        [0.73199394, 0.59865848],\n",
       "        [0.15601864, 0.15599452],\n",
       "        [0.05808361, 0.86617615],\n",
       "        [0.60111501, 0.70807258]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X = np.random.uniform(0, 1, size=(1000,2))\n",
    "X.shape, X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = np.random.normal(0, 1, size=1000)\n",
    "epsilon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Terrible solution, but the dataset was terribly formatted to begin with\n",
    "X1 = np.array([X[i][0] for i in range(len(X))])\n",
    "X2 = np.array([X[i][1] for i in range(len(X))])\n",
    "\n",
    "y = 3 * X1 + 5 * X2 + 3 + epsilon\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.        , 0.37454012, 0.95071431],\n",
       "        [1.        , 0.73199394, 0.59865848],\n",
       "        [1.        , 0.15601864, 0.15599452]]),\n",
       " (1000, 3))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.c_[np.ones(len(X)), X]\n",
    "X[0:3], X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((670, 3), (330, 3), (670,), (330,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape # X has two columns, so shape is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.16440925, 3.03763668, 4.82471836])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def gradient_descent(X, y, learning_rate=0.1, epochs=100):\n",
    "    m = len(X)\n",
    "    \n",
    "    # Create random b0 & b1\n",
    "    theta = np.random.randn(X.shape[1], 1)  # [beta_0, beta_1]^T - [2x1]\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        # Get gradient (slope)\n",
    "        gradient = 2 / m * X.T @ (X @ theta - y) # idk\n",
    "        \n",
    "        # determine step size and use it next time we loop\n",
    "        theta -= learning_rate*gradient # learning_rate is eta in theory\n",
    "    return theta\n",
    "\n",
    "# Get estimated b0 and b1 values by actually doing the batch gradient descent\n",
    "theta = gradient_descent(X_train, y_train, epochs=1000, learning_rate=0.1)\n",
    "\n",
    "theta.reshape(-1) # throws away additional dimension\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Code-CYgrxAwh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d154d3528bab554518fce4b6bb47c23f2c1c42d729e7fb7463b0619040c8c50c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
